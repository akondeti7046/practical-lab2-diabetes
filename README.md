# Practical Lab 2 â€“ Predicting Diabetes Progression using Machine Learning

## ğŸ” Objective

This lab explores the **Scikit-learn Diabetes dataset** to predict the risk of diabetes progression. The aim is to build and compare different machine learning models to identify the most effective one for predicting disease progression one year after baseline.

## ğŸ“ Dataset

- **Source**: `sklearn.datasets.load_diabetes()`
- The dataset consists of 442 samples and 10 input features (normalized).
- Target variable: a quantitative measure of disease progression after one year.

## ğŸ§ª Models Implemented

### ğŸ§µ Univariate Polynomial Regression
- Feature: BMI
- Degrees: 0 to 5
- Evaluated using: RÂ², MAE, MAPE
- Best: Degree 5 (test RÂ² â‰ˆ 0.27)

### ğŸ”¢ Multivariate Polynomial Regression
- Degrees: 2 and 3
- Observed overfitting and instability

### ğŸŒ² Decision Tree Regression
- Depths: 3 and 5
- Best validation RÂ² at depth 3

### ğŸ‘¥ k-Nearest Neighbors (kNN)
- Values: k=3, k=5
- Best performance with k=5 (Val RÂ² â‰ˆ 0.36)

## ğŸ“Š Evaluation Metrics
- RÂ² (R-squared)
- MAE (Mean Absolute Error)
- MAPE (Mean Absolute Percentage Error)

## ğŸ” Key Insights
- BMI alone is insufficient to explain most variance in diabetes progression.
- kNN with k=5 generalized better than other models.
- Feature interactions may be complex; further feature engineering and advanced models are recommended.

## ğŸ“ Files Included
- `Practical Lab 2.ipynb`: Jupyter notebook with all code, models, and results.
- `requirements.txt`: Python dependencies for reproducibility.
- `README.md`: This project overview.

## ğŸ§  Future Improvements
- Add cross-validation for more robust model evaluation.
- Experiment with ensemble methods (Random Forest, Gradient Boosting).
- Perform hyperparameter tuning.

## ğŸ“Œ Author
**Adhitya Kondeti**  
Student ID: 8997046  
Conestoga College â€“ Artificial Intelligence and Machine Learning
This is a new line added directly via terminal at Mon Jul  7 14:44:09 EDT 2025
